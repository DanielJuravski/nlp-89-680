=====================================================================
This file describes how to run the Similarity Computation & Word2Vec.
=====================================================================

Required libraries...: 'prettytable'
Why..................:  nice printing of results.
How..................:  'pip install prettytable'


-----------------------
Similarity Computation:
-----------------------
Motivation:
    1.  Start with parsing the data:
        1.1 Convert the 'wikipedia trees lemmatized' to 2 files.
            file1: pairs of 'word attribute'
            file2: words (that appeared over specified threshold) and their count of appearance.
        1.2 Sort file1 and write it to file3, the result is triples of 'word attribute count_of_appearance'
            The triples that written will be only the ones that appeared over specified threshold.
    2.  Run the 'similarity_computation.py' script that gets file3, file2, type of co-occurrence (sentence, window, dependency),
        and print the 20 closest words and 20 top contexts.

Command Line:
    1.
        1.1 python init_parse.py <parse_type> <input_file> <output_pairs_file> <output_word_file> <word_appearance_threshold>
            For example: $python init_parse.py window wikipedia.sample.trees.lemmatized data_parsed data_words 100
            (Where <parse_type> can be ['all', 'window', 'dep'])
        1.2 sh count_and_sort_filter.sh <input_parsed_file> <pairs_threshold> <output_triples_file>
            For example: sh count_and_sort_filter.sh data_parsed 5 data_sorted
    2.  python similarity_computation.py <output_triples_file> <output_word_file>
        For example: python similarity_computation.py data_sorted data_words


---------
Word2Vec:
---------

Command Line:
    python close_words.py <bow5_words_file> <deps_words_file> <bow5_contexts_file>  <deps_contexts_file>

This program write the outputs to 2 files:
    1. 'word2vec_closets_words'
    2. 'word2vec_strongest_contexts'
